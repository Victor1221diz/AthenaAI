{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Exact Match (EM)': 0.0, 'Precision': 0.0006016544280409443, 'Recall': 0.0006016544280409443, 'F1 Score': 0.0006016544280409443, 'ROUGE': [{'rouge1': Score(precision=0.024844720496894408, recall=0.5925925925925926, fmeasure=0.04769001490312965), 'rougeL': Score(precision=0.023291925465838508, recall=0.5555555555555556, fmeasure=0.044709388971684055)}, {'rouge1': Score(precision=0.026836158192090395, recall=0.5757575757575758, fmeasure=0.05128205128205128), 'rougeL': Score(precision=0.022598870056497175, recall=0.48484848484848486, fmeasure=0.043184885290148446)}, {'rouge1': Score(precision=0.04239766081871345, recall=0.725, fmeasure=0.08011049723756906), 'rougeL': Score(precision=0.03654970760233918, recall=0.625, fmeasure=0.06906077348066297)}, {'rouge1': Score(precision=0.029239766081871343, recall=0.5128205128205128, fmeasure=0.055325034578146616), 'rougeL': Score(precision=0.02631578947368421, recall=0.46153846153846156, fmeasure=0.049792531120331954)}, {'rouge1': Score(precision=0.0136986301369863, recall=0.38095238095238093, fmeasure=0.026446280991735537), 'rougeL': Score(precision=0.0136986301369863, recall=0.38095238095238093, fmeasure=0.026446280991735537)}, {'rouge1': Score(precision=0.05457746478873239, recall=0.9393939393939394, fmeasure=0.10316139767054908), 'rougeL': Score(precision=0.05457746478873239, recall=0.9393939393939394, fmeasure=0.10316139767054908)}, {'rouge1': Score(precision=0.05080213903743316, recall=0.9047619047619048, fmeasure=0.09620253164556962), 'rougeL': Score(precision=0.04679144385026738, recall=0.8333333333333334, fmeasure=0.08860759493670886)}, {'rouge1': Score(precision=0.0427807486631016, recall=0.9411764705882353, fmeasure=0.08184143222506395), 'rougeL': Score(precision=0.0427807486631016, recall=0.9411764705882353, fmeasure=0.08184143222506395)}, {'rouge1': Score(precision=0.04391891891891892, recall=0.9629629629629629, fmeasure=0.08400646203554119), 'rougeL': Score(precision=0.04391891891891892, recall=0.9629629629629629, fmeasure=0.08400646203554119)}, {'rouge1': Score(precision=0.04054054054054054, recall=0.96, fmeasure=0.07779578606158832), 'rougeL': Score(precision=0.04054054054054054, recall=0.96, fmeasure=0.07779578606158832)}, {'rouge1': Score(precision=0.02949438202247191, recall=0.9130434782608695, fmeasure=0.05714285714285715), 'rougeL': Score(precision=0.02949438202247191, recall=0.9130434782608695, fmeasure=0.05714285714285715)}, {'rouge1': Score(precision=0.043243243243243246, recall=1.0, fmeasure=0.08290155440414508), 'rougeL': Score(precision=0.041891891891891894, recall=0.96875, fmeasure=0.08031088082901557)}, {'rouge1': Score(precision=0.033707865168539325, recall=0.8888888888888888, fmeasure=0.06495263870094722), 'rougeL': Score(precision=0.03089887640449438, recall=0.8148148148148148, fmeasure=0.05953991880920162)}, {'rouge1': Score(precision=0.023809523809523808, recall=0.6363636363636364, fmeasure=0.04590163934426229), 'rougeL': Score(precision=0.02040816326530612, recall=0.5454545454545454, fmeasure=0.039344262295081964)}, {'rouge1': Score(precision=0.016304347826086956, recall=0.6666666666666666, fmeasure=0.03183023872679045), 'rougeL': Score(precision=0.016304347826086956, recall=0.6666666666666666, fmeasure=0.03183023872679045)}, {'rouge1': Score(precision=0.029239766081871343, recall=0.9523809523809523, fmeasure=0.056737588652482275), 'rougeL': Score(precision=0.029239766081871343, recall=0.9523809523809523, fmeasure=0.056737588652482275)}, {'rouge1': Score(precision=0.016483516483516484, recall=0.7058823529411765, fmeasure=0.03221476510067114), 'rougeL': Score(precision=0.016483516483516484, recall=0.7058823529411765, fmeasure=0.03221476510067114)}, {'rouge1': Score(precision=0.026470588235294117, recall=0.6923076923076923, fmeasure=0.0509915014164306), 'rougeL': Score(precision=0.026470588235294117, recall=0.6923076923076923, fmeasure=0.0509915014164306)}, {'rouge1': Score(precision=0.033950617283950615, recall=0.9565217391304348, fmeasure=0.06557377049180327), 'rougeL': Score(precision=0.033950617283950615, recall=0.9565217391304348, fmeasure=0.06557377049180327)}, {'rouge1': Score(precision=0.034210526315789476, recall=0.896551724137931, fmeasure=0.06590621039290241), 'rougeL': Score(precision=0.034210526315789476, recall=0.896551724137931, fmeasure=0.06590621039290241)}, {'rouge1': Score(precision=0.01694915254237288, recall=0.5454545454545454, fmeasure=0.03287671232876713), 'rougeL': Score(precision=0.01694915254237288, recall=0.5454545454545454, fmeasure=0.03287671232876713)}, {'rouge1': Score(precision=0.028901734104046242, recall=0.625, fmeasure=0.05524861878453038), 'rougeL': Score(precision=0.02601156069364162, recall=0.5625, fmeasure=0.04972375690607735)}, {'rouge1': Score(precision=0.010606060606060607, recall=0.5833333333333334, fmeasure=0.020833333333333336), 'rougeL': Score(precision=0.010606060606060607, recall=0.5833333333333334, fmeasure=0.020833333333333336)}, {'rouge1': Score(precision=0.019444444444444445, recall=0.6363636363636364, fmeasure=0.03773584905660377), 'rougeL': Score(precision=0.018055555555555554, recall=0.5909090909090909, fmeasure=0.035040431266846354)}, {'rouge1': Score(precision=0.028089887640449437, recall=0.9523809523809523, fmeasure=0.05457025920873124), 'rougeL': Score(precision=0.028089887640449437, recall=0.9523809523809523, fmeasure=0.05457025920873124)}, {'rouge1': Score(precision=0.0211864406779661, recall=0.6521739130434783, fmeasure=0.04103967168262654), 'rougeL': Score(precision=0.0211864406779661, recall=0.6521739130434783, fmeasure=0.04103967168262654)}, {'rouge1': Score(precision=0.025280898876404494, recall=1.0, fmeasure=0.04931506849315069), 'rougeL': Score(precision=0.025280898876404494, recall=1.0, fmeasure=0.04931506849315069)}, {'rouge1': Score(precision=0.013736263736263736, recall=0.625, fmeasure=0.02688172043010753), 'rougeL': Score(precision=0.013736263736263736, recall=0.625, fmeasure=0.02688172043010753)}, {'rouge1': Score(precision=0.01744186046511628, recall=0.6, fmeasure=0.03389830508474576), 'rougeL': Score(precision=0.015988372093023256, recall=0.55, fmeasure=0.031073446327683617)}, {'rouge1': Score(precision=0.02245508982035928, recall=0.625, fmeasure=0.04335260115606936), 'rougeL': Score(precision=0.02245508982035928, recall=0.625, fmeasure=0.04335260115606936)}, {'rouge1': Score(precision=0.020348837209302327, recall=0.875, fmeasure=0.03977272727272727), 'rougeL': Score(precision=0.020348837209302327, recall=0.875, fmeasure=0.03977272727272727)}, {'rouge1': Score(precision=0.019662921348314606, recall=0.7368421052631579, fmeasure=0.038303693570451436), 'rougeL': Score(precision=0.019662921348314606, recall=0.7368421052631579, fmeasure=0.038303693570451436)}, {'rouge1': Score(precision=0.016176470588235296, recall=1.0, fmeasure=0.031837916063675836), 'rougeL': Score(precision=0.016176470588235296, recall=1.0, fmeasure=0.031837916063675836)}, {'rouge1': Score(precision=0.023529411764705882, recall=0.8, fmeasure=0.045714285714285714), 'rougeL': Score(precision=0.023529411764705882, recall=0.8, fmeasure=0.045714285714285714)}, {'rouge1': Score(precision=0.011764705882352941, recall=0.5333333333333333, fmeasure=0.02302158273381295), 'rougeL': Score(precision=0.011764705882352941, recall=0.5333333333333333, fmeasure=0.02302158273381295)}, {'rouge1': Score(precision=0.016176470588235296, recall=0.7857142857142857, fmeasure=0.03170028818443804), 'rougeL': Score(precision=0.016176470588235296, recall=0.7857142857142857, fmeasure=0.03170028818443804)}, {'rouge1': Score(precision=0.029320987654320986, recall=0.9047619047619048, fmeasure=0.05680119581464873), 'rougeL': Score(precision=0.029320987654320986, recall=0.9047619047619048, fmeasure=0.05680119581464873)}, {'rouge1': Score(precision=0.020942408376963352, recall=0.5925925925925926, fmeasure=0.040455120101137804), 'rougeL': Score(precision=0.020942408376963352, recall=0.5925925925925926, fmeasure=0.040455120101137804)}, {'rouge1': Score(precision=0.03017241379310345, recall=0.875, fmeasure=0.058333333333333334), 'rougeL': Score(precision=0.03017241379310345, recall=0.875, fmeasure=0.058333333333333334)}, {'rouge1': Score(precision=0.03508771929824561, recall=0.96, fmeasure=0.06770098730606489), 'rougeL': Score(precision=0.03508771929824561, recall=0.96, fmeasure=0.06770098730606489)}, {'rouge1': Score(precision=0.02531645569620253, recall=0.7619047619047619, fmeasure=0.04900459418070444), 'rougeL': Score(precision=0.02531645569620253, recall=0.7619047619047619, fmeasure=0.04900459418070444)}, {'rouge1': Score(precision=0.02702702702702703, recall=0.8333333333333334, fmeasure=0.05235602094240838), 'rougeL': Score(precision=0.024324324324324326, recall=0.75, fmeasure=0.04712041884816754)}, {'rouge1': Score(precision=0.0188953488372093, recall=0.5, fmeasure=0.03641456582633053), 'rougeL': Score(precision=0.0188953488372093, recall=0.5, fmeasure=0.03641456582633053)}, {'rouge1': Score(precision=0.02702702702702703, recall=0.625, fmeasure=0.051813471502590684), 'rougeL': Score(precision=0.025675675675675677, recall=0.59375, fmeasure=0.04922279792746114)}, {'rouge1': Score(precision=0.020833333333333332, recall=0.6086956521739131, fmeasure=0.04028776978417266), 'rougeL': Score(precision=0.019345238095238096, recall=0.5652173913043478, fmeasure=0.03741007194244604)}, {'rouge1': Score(precision=0.019345238095238096, recall=0.41935483870967744, fmeasure=0.03698435277382646), 'rougeL': Score(precision=0.017857142857142856, recall=0.3870967741935484, fmeasure=0.03413940256045519)}, {'rouge1': Score(precision=0.03313253012048193, recall=0.9565217391304348, fmeasure=0.06404657933042213), 'rougeL': Score(precision=0.02710843373493976, recall=0.782608695652174, fmeasure=0.052401746724890834)}, {'rouge1': Score(precision=0.021929824561403508, recall=0.5769230769230769, fmeasure=0.04225352112676056), 'rougeL': Score(precision=0.02046783625730994, recall=0.5384615384615384, fmeasure=0.039436619718309855)}, {'rouge1': Score(precision=0.019345238095238096, recall=0.65, fmeasure=0.03757225433526011), 'rougeL': Score(precision=0.017857142857142856, recall=0.6, fmeasure=0.03468208092485549)}, {'rouge1': Score(precision=0.019230769230769232, recall=0.7777777777777778, fmeasure=0.03753351206434316), 'rougeL': Score(precision=0.019230769230769232, recall=0.7777777777777778, fmeasure=0.03753351206434316)}, {'rouge1': Score(precision=0.01957831325301205, recall=0.65, fmeasure=0.038011695906432746), 'rougeL': Score(precision=0.01957831325301205, recall=0.65, fmeasure=0.038011695906432746)}, {'rouge1': Score(precision=0.01544943820224719, recall=0.55, fmeasure=0.03005464480874317), 'rougeL': Score(precision=0.01544943820224719, recall=0.55, fmeasure=0.03005464480874317)}, {'rouge1': Score(precision=0.01911764705882353, recall=0.6190476190476191, fmeasure=0.037089871611982884), 'rougeL': Score(precision=0.01764705882352941, recall=0.5714285714285714, fmeasure=0.03423680456490727)}, {'rouge1': Score(precision=0.020958083832335328, recall=0.6363636363636364, fmeasure=0.04057971014492753), 'rougeL': Score(precision=0.020958083832335328, recall=0.6363636363636364, fmeasure=0.04057971014492753)}, {'rouge1': Score(precision=0.032303370786516857, recall=0.8518518518518519, fmeasure=0.06224627875507443), 'rougeL': Score(precision=0.032303370786516857, recall=0.8518518518518519, fmeasure=0.06224627875507443)}, {'rouge1': Score(precision=0.02976190476190476, recall=0.8333333333333334, fmeasure=0.057471264367816084), 'rougeL': Score(precision=0.02976190476190476, recall=0.8333333333333334, fmeasure=0.057471264367816084)}, {'rouge1': Score(precision=0.033625730994152045, recall=0.8846153846153846, fmeasure=0.0647887323943662), 'rougeL': Score(precision=0.029239766081871343, recall=0.7692307692307693, fmeasure=0.05633802816901408)}, {'rouge1': Score(precision=0.01881720430107527, recall=0.5, fmeasure=0.036269430051813475), 'rougeL': Score(precision=0.01881720430107527, recall=0.5, fmeasure=0.036269430051813475)}, {'rouge1': Score(precision=0.019230769230769232, recall=0.5, fmeasure=0.037037037037037035), 'rougeL': Score(precision=0.016272189349112426, recall=0.4230769230769231, fmeasure=0.03133903133903134)}, {'rouge1': Score(precision=0.02197802197802198, recall=0.7619047619047619, fmeasure=0.04272363150867824), 'rougeL': Score(precision=0.02197802197802198, recall=0.7619047619047619, fmeasure=0.04272363150867824)}, {'rouge1': Score(precision=0.01912568306010929, recall=0.5833333333333334, fmeasure=0.037037037037037035), 'rougeL': Score(precision=0.01912568306010929, recall=0.5833333333333334, fmeasure=0.037037037037037035)}, {'rouge1': Score(precision=0.01744186046511628, recall=0.6, fmeasure=0.03389830508474576), 'rougeL': Score(precision=0.01744186046511628, recall=0.6, fmeasure=0.03389830508474576)}, {'rouge1': Score(precision=0.03765060240963856, recall=0.9259259259259259, fmeasure=0.07235890014471781), 'rougeL': Score(precision=0.03313253012048193, recall=0.8148148148148148, fmeasure=0.06367583212735167)}, {'rouge1': Score(precision=0.025, recall=0.5862068965517241, fmeasure=0.047954866008462625), 'rougeL': Score(precision=0.023529411764705882, recall=0.5517241379310345, fmeasure=0.045133991537376586)}, {'rouge1': Score(precision=0.03070175438596491, recall=0.84, fmeasure=0.05923836389280677), 'rougeL': Score(precision=0.029239766081871343, recall=0.8, fmeasure=0.05641748942172073)}, {'rouge1': Score(precision=0.028145695364238412, recall=0.6071428571428571, fmeasure=0.05379746835443039), 'rougeL': Score(precision=0.028145695364238412, recall=0.6071428571428571, fmeasure=0.05379746835443039)}, {'rouge1': Score(precision=0.03278688524590164, recall=0.8888888888888888, fmeasure=0.06324110671936758), 'rougeL': Score(precision=0.03278688524590164, recall=0.8888888888888888, fmeasure=0.06324110671936758)}, {'rouge1': Score(precision=0.034210526315789476, recall=0.7222222222222222, fmeasure=0.06532663316582915), 'rougeL': Score(precision=0.034210526315789476, recall=0.7222222222222222, fmeasure=0.06532663316582915)}, {'rouge1': Score(precision=0.024844720496894408, recall=0.64, fmeasure=0.04783258594917787), 'rougeL': Score(precision=0.021739130434782608, recall=0.56, fmeasure=0.04185351270553064)}, {'rouge1': Score(precision=0.02894736842105263, recall=0.7857142857142857, fmeasure=0.05583756345177666), 'rougeL': Score(precision=0.02894736842105263, recall=0.7857142857142857, fmeasure=0.05583756345177666)}, {'rouge1': Score(precision=0.028846153846153848, recall=0.8076923076923077, fmeasure=0.05570291777188329), 'rougeL': Score(precision=0.028846153846153848, recall=0.8076923076923077, fmeasure=0.05570291777188329)}, {'rouge1': Score(precision=0.033823529411764704, recall=0.8518518518518519, fmeasure=0.06506364922206506), 'rougeL': Score(precision=0.033823529411764704, recall=0.8518518518518519, fmeasure=0.06506364922206506)}, {'rouge1': Score(precision=0.03235294117647059, recall=0.8461538461538461, fmeasure=0.062322946175637405), 'rougeL': Score(precision=0.03235294117647059, recall=0.8461538461538461, fmeasure=0.062322946175637405)}, {'rouge1': Score(precision=0.03235294117647059, recall=0.7096774193548387, fmeasure=0.0618846694796062), 'rougeL': Score(precision=0.029411764705882353, recall=0.6451612903225806, fmeasure=0.05625879043600562)}, {'rouge1': Score(precision=0.03216374269005848, recall=1.0, fmeasure=0.06232294617563739), 'rougeL': Score(precision=0.03216374269005848, recall=1.0, fmeasure=0.06232294617563739)}, {'rouge1': Score(precision=0.03415300546448088, recall=0.8928571428571429, fmeasure=0.06578947368421054), 'rougeL': Score(precision=0.03415300546448088, recall=0.8928571428571429, fmeasure=0.06578947368421054)}, {'rouge1': Score(precision=0.01818181818181818, recall=0.6, fmeasure=0.03529411764705882), 'rougeL': Score(precision=0.016666666666666666, recall=0.55, fmeasure=0.032352941176470584)}, {'rouge1': Score(precision=0.023291925465838508, recall=0.6818181818181818, fmeasure=0.04504504504504504), 'rougeL': Score(precision=0.018633540372670808, recall=0.5454545454545454, fmeasure=0.036036036036036036)}, {'rouge1': Score(precision=0.03162650602409638, recall=0.84, fmeasure=0.06095791001451378), 'rougeL': Score(precision=0.030120481927710843, recall=0.8, fmeasure=0.05805515239477503)}, {'rouge1': Score(precision=0.021144278606965175, recall=0.7083333333333334, fmeasure=0.04106280193236715), 'rougeL': Score(precision=0.021144278606965175, recall=0.7083333333333334, fmeasure=0.04106280193236715)}, {'rouge1': Score(precision=0.02309782608695652, recall=0.68, fmeasure=0.04467805519053876), 'rougeL': Score(precision=0.020380434782608696, recall=0.6, fmeasure=0.039421813403416564)}, {'rouge1': Score(precision=0.023351648351648352, recall=0.6296296296296297, fmeasure=0.045033112582781455), 'rougeL': Score(precision=0.023351648351648352, recall=0.6296296296296297, fmeasure=0.045033112582781455)}, {'rouge1': Score(precision=0.01977401129943503, recall=0.6086956521739131, fmeasure=0.03830369357045144), 'rougeL': Score(precision=0.018361581920903956, recall=0.5652173913043478, fmeasure=0.03556771545827633)}, {'rouge1': Score(precision=0.02745664739884393, recall=0.6129032258064516, fmeasure=0.05255878284923929), 'rougeL': Score(precision=0.023121387283236993, recall=0.5161290322580645, fmeasure=0.044260027662517284)}, {'rouge1': Score(precision=0.019662921348314606, recall=0.56, fmeasure=0.037991858887381276), 'rougeL': Score(precision=0.019662921348314606, recall=0.56, fmeasure=0.037991858887381276)}, {'rouge1': Score(precision=0.022321428571428572, recall=0.6, fmeasure=0.0430416068866571), 'rougeL': Score(precision=0.022321428571428572, recall=0.6, fmeasure=0.0430416068866571)}, {'rouge1': Score(precision=0.02717391304347826, recall=0.7692307692307693, fmeasure=0.05249343832020997), 'rougeL': Score(precision=0.025815217391304348, recall=0.7307692307692307, fmeasure=0.049868766404199474)}, {'rouge1': Score(precision=0.0377906976744186, recall=0.896551724137931, fmeasure=0.07252440725244072), 'rougeL': Score(precision=0.036337209302325583, recall=0.8620689655172413, fmeasure=0.0697350069735007)}, {'rouge1': Score(precision=0.037162162162162164, recall=1.0, fmeasure=0.0716612377850163), 'rougeL': Score(precision=0.037162162162162164, recall=1.0, fmeasure=0.0716612377850163)}, {'rouge1': Score(precision=0.020053475935828877, recall=0.5555555555555556, fmeasure=0.03870967741935484), 'rougeL': Score(precision=0.01871657754010695, recall=0.5185185185185185, fmeasure=0.03612903225806451)}, {'rouge1': Score(precision=0.01867816091954023, recall=0.7647058823529411, fmeasure=0.0364656381486676), 'rougeL': Score(precision=0.017241379310344827, recall=0.7058823529411765, fmeasure=0.033660589060308554)}, {'rouge1': Score(precision=0.020053475935828877, recall=0.6521739130434783, fmeasure=0.038910505836575876), 'rougeL': Score(precision=0.020053475935828877, recall=0.6521739130434783, fmeasure=0.038910505836575876)}, {'rouge1': Score(precision=0.028225806451612902, recall=0.7777777777777778, fmeasure=0.054474708171206226), 'rougeL': Score(precision=0.026881720430107527, recall=0.7407407407407407, fmeasure=0.05188067444876784)}, {'rouge1': Score(precision=0.024709302325581394, recall=0.6071428571428571, fmeasure=0.047486033519553064), 'rougeL': Score(precision=0.024709302325581394, recall=0.6071428571428571, fmeasure=0.047486033519553064)}, {'rouge1': Score(precision=0.025423728813559324, recall=0.72, fmeasure=0.04911323328785811), 'rougeL': Score(precision=0.025423728813559324, recall=0.72, fmeasure=0.04911323328785811)}, {'rouge1': Score(precision=0.0223463687150838, recall=0.8888888888888888, fmeasure=0.04359673024523161), 'rougeL': Score(precision=0.0223463687150838, recall=0.8888888888888888, fmeasure=0.04359673024523161)}, {'rouge1': Score(precision=0.02710843373493976, recall=0.6923076923076923, fmeasure=0.05217391304347826), 'rougeL': Score(precision=0.02710843373493976, recall=0.6923076923076923, fmeasure=0.05217391304347826)}, {'rouge1': Score(precision=0.016272189349112426, recall=0.4230769230769231, fmeasure=0.03133903133903134), 'rougeL': Score(precision=0.016272189349112426, recall=0.4230769230769231, fmeasure=0.03133903133903134)}, {'rouge1': Score(precision=0.031073446327683617, recall=0.7096774193548387, fmeasure=0.05953991880920163), 'rougeL': Score(precision=0.029661016949152543, recall=0.6774193548387096, fmeasure=0.056833558863328824)}, {'rouge1': Score(precision=0.02638888888888889, recall=0.6785714285714286, fmeasure=0.05080213903743316), 'rougeL': Score(precision=0.02361111111111111, recall=0.6071428571428571, fmeasure=0.04545454545454545)}], 'Disambig-F1': 0.49305401772260665}\n"
     ]
    }
   ],
   "source": [
    "import PyPDF2\n",
    "import pandas as pd\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from rouge_score import rouge_scorer\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "import torch\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain import hub\n",
    "\n",
    "# Function to load PDF using PdfReader\n",
    "def load_pdf(file_path):\n",
    "    with open(file_path, 'rb') as file:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "        text = \"\"\n",
    "        for page in reader.pages:\n",
    "            text += page.extract_text()\n",
    "    return text\n",
    "\n",
    "# Load the PDF\n",
    "pdf_text = load_pdf('example.pdf')\n",
    "\n",
    "# Convert the loaded text to Document objects\n",
    "documents = [Document(page_content=pdf_text, metadata={\"source\": \"PDF\"})]\n",
    "\n",
    "# Split the text into chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(documents)\n",
    "\n",
    "# Embed the documents\n",
    "vectorstore = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# Prompt\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "# LLM\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "# Simulated FLARE mechanism\n",
    "def flare_retrieve(question):\n",
    "    initial_result = retriever.vectorstore.similarity_search(question)\n",
    "    \n",
    "    # Here, we assume a simplistic confidence mechanism where we re-query if the initial response is short or lacking context.\n",
    "    if len(initial_result[0].page_content) < 100:  # This threshold can be adjusted\n",
    "        follow_up_query = f\"Can you provide more details about: {question}\"\n",
    "        detailed_query = llm(follow_up_query, context=initial_result)\n",
    "        return retriever.vectorstore.similarity_search(detailed_query)\n",
    "    return initial_result\n",
    "\n",
    "# Function to generate answers using RAG with FLARE mechanism\n",
    "def generate_answer(question):\n",
    "    results = flare_retrieve(question)\n",
    "    return \" \".join([doc.page_content for doc in results])\n",
    "\n",
    "# Function to align tokens with padding or trimming\n",
    "def align_tokens(actual, generated):\n",
    "    actual_tokens = actual.split()\n",
    "    generated_tokens = generated.split()\n",
    "    \n",
    "    max_len = max(len(actual_tokens), len(generated_tokens))\n",
    "    \n",
    "    # Pad or trim tokens to the same length\n",
    "    if len(actual_tokens) < max_len:\n",
    "        actual_tokens.extend(['<PAD>'] * (max_len - len(actual_tokens)))\n",
    "    elif len(actual_tokens) > max_len:\n",
    "        actual_tokens = actual_tokens[:max_len]\n",
    "    \n",
    "    if len(generated_tokens) < max_len:\n",
    "        generated_tokens.extend(['<PAD>'] * (max_len - len(generated_tokens)))\n",
    "    elif len(generated_tokens) > max_len:\n",
    "        generated_tokens = generated_tokens[:max_len]\n",
    "    \n",
    "    return actual_tokens, generated_tokens\n",
    "\n",
    "# Function to compute evaluation metrics\n",
    "def compute_metrics(actual_answers, generated_answers):\n",
    "    em_scores = []\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "    f1_scores = []\n",
    "    rouge_scores = []\n",
    "    disambig_f1_scores = []\n",
    "\n",
    "    tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "    model = RobertaForSequenceClassification.from_pretrained(\"roberta-base\")\n",
    "\n",
    "    for actual, generated in zip(actual_answers, generated_answers):\n",
    "        # Exact Match\n",
    "        em_scores.append(actual == generated)\n",
    "        \n",
    "        # Token-level Precision, Recall, F1\n",
    "        aligned_actual, aligned_generated = align_tokens(actual, generated)\n",
    "        \n",
    "        precision = precision_score(aligned_actual, aligned_generated, average='micro', zero_division=1)\n",
    "        recall = recall_score(aligned_actual, aligned_generated, average='micro', zero_division=1)\n",
    "        f1 = f1_score(aligned_actual, aligned_generated, average='micro', zero_division=1)\n",
    "        \n",
    "        precision_scores.append(precision)\n",
    "        recall_scores.append(recall)\n",
    "        f1_scores.append(f1)\n",
    "        \n",
    "        # ROUGE Scores\n",
    "        scorer = rouge_scorer.RougeScorer(['rouge1', 'rougeL'], use_stemmer=True)\n",
    "        rouge = scorer.score(actual, generated)\n",
    "        rouge_scores.append(rouge)\n",
    "        \n",
    "        # Disambig-F1\n",
    "        inputs = tokenizer.encode_plus(actual, generated, truncation=True, padding='max_length', max_length=512, return_tensors=\"pt\")\n",
    "        outputs = model(**inputs)\n",
    "        probs = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "        disambig_f1 = probs[0][1].item()\n",
    "        disambig_f1_scores.append(disambig_f1)\n",
    "    \n",
    "    metrics = {\n",
    "        \"Exact Match (EM)\": sum(em_scores) / len(em_scores),\n",
    "        \"Precision\": sum(precision_scores) / len(precision_scores),\n",
    "        \"Recall\": sum(recall_scores) / len(recall_scores),\n",
    "        \"F1 Score\": sum(f1_scores) / len(f1_scores),\n",
    "        \"ROUGE\": rouge_scores,\n",
    "        \"Disambig-F1\": sum(disambig_f1_scores) / len(disambig_f1_scores)\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Function to test RAG with questions from CSV and compute metrics\n",
    "def test_rag_with_csv(csv_file_path):\n",
    "    # Load the CSV file\n",
    "    df = pd.read_csv(csv_file_path)\n",
    "    \n",
    "    # Ensure CSV has 'Question' and 'Answer' columns\n",
    "    if 'Question' not in df.columns or 'Answer' not in df.columns:\n",
    "        raise ValueError(\"CSV file must contain 'Question' and 'Answer' columns.\")\n",
    "    \n",
    "    # Generate answers using RAG and compare with actual answers\n",
    "    actual_answers = []\n",
    "    generated_answers = []\n",
    "    for index, row in df.iterrows():\n",
    "        question = row['Question']\n",
    "        actual_answer = row['Answer']\n",
    "        \n",
    "        generated_answer = generate_answer(question)\n",
    "        \n",
    "        actual_answers.append(actual_answer)\n",
    "        generated_answers.append(generated_answer)\n",
    "    \n",
    "    # Compute metrics\n",
    "    metrics = compute_metrics(actual_answers, generated_answers)\n",
    "    return metrics\n",
    "\n",
    "csv_file_path = \"question_answers.csv\"\n",
    "metrics = test_rag_with_csv(csv_file_path)\n",
    "print(metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
